TOKENIZERS_PARALLELISM=false python3 pred.py --model "Llama-3.1-8B-Instruct" --n_proc 1 -if 2000 2>&1 | tee output.log
70/261 answers correct
242 API errors (including where we had too many tokens)