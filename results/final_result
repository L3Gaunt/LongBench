TOKENIZERS_PARALLELISM=false python3 pred.py --model "Llama-3.1-8B-Instruct" --n_proc 1 2>&1 | tee output.log)
94/284 answers correct
219 API errors (including where we had too many tokens)