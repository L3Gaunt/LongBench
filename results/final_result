TOKENIZERS_PARALLELISM=false python3 pred.py --model "Llama-3.1-8B-Instruct" --n_proc 1 2>&1 | tee output.log)
*/* correct answers
* API errors (including where we had too many tokens)